# DaRk Side of LLM Resources

LLMs have indeed reached a point of diminishing returns
https://garymarcus.substack.com/p/confirmed-llms-have-indeed-reached

Coding on Copilot: 2023 Data Suggests Downward Pressure on Code Quality (research 2023)
https://www.gitclear.com/coding_on_copilot_data_shows_ais_downward_pressure_on_code_quality

Research Summary (New GitHub Copilot Research Finds 'Downward Pressure on Code Quality')
https://visualstudiomagazine.com/articles/2024/01/25/copilot-research.aspx
Findings:
- Less Moved Code Implies Less Refactoring, Less Reuse
- More Copy/Pasted Code Implies Future Headaches

Multimodal prompt injection image attacks
https://venturebeat.com/security/why-gpt-4-is-vulnerable-to-multimodal-prompt-injection-image-attacks/

51.24% of the samples from the 112,000 C programs contain vulnerabilities
https://www.linkedin.com/pulse/code-red-large-scale-study-chatgpt-generated-vulnerabilities-z81cf/?trk=article-ssr-frontend-pulse_more-articles_related-content-card

ChatGPT creates mostly insecure code, but won't tell you unless you ask
https://www.theregister.com/2023/04/21/chatgpt_insecure_code/

Risks of LLMs
https://deepchecks.com/risks-of-large-language-models/

Better Call GPT, Comparing Large Language Models Against Lawyers
https://arxiv.org/pdf/2401.16212.pdf

FCC Makes AI-Generated Voices in Robocalls Illegal
https://www.fcc.gov/document/fcc-makes-ai-generated-voices-robocalls-illegal

Tech companies axe 34,000 jobs since the start of the year in pivot to AI
https://www.ft.com/content/9bace2e9-3ecb-4651-a6c0-b16f0226c0e0

Air Canada must pay damages after chatbot lies to grieving passenger about discount
https://www.theregister.com/2024/02/15/air_canada_chatbot_fine/

Air Canada ordered to pay a customer who was misled by airline’s chatbot
https://www.theguardian.com/world/2024/feb/16/air-canada-chatbot-lawsuit

Google CEO calls AI tool’s controversial responses ‘completely unacceptable’
https://www.semafor.com/article/02/27/2024/google-ceo-sundar-pichai-calls-ai-tools-responses-completely-unacceptable

Google's Gemini can't show me the fastest way to copy memory in c# because it's unethical.
https://twitter.com/garrynewman/status/1755851884047303012

Gemini thinks C++ is too dangerous for under 18-year-olds
https://gemini.google.com/share/238032386438?hl=en

AI Hype is completely out of control - especially since ChatGPT-4o
https://www.youtube.com/watch?v=VctsqOo8wsc&ab_channel=InternetofBugs

Is GenAI’s Impact on Productivity Overblown?
https://hbr.org/2024/01/is-genais-impact-on-productivity-overblown
- Generative AI could grow corporate profits globally by $4.4 trillion annually
- Nielsen trumpeted a 66% increase in employee productivity
	- https://www.mckinsey.com/mgi/overview/in-the-news/ai-could-increase-corporate-profits-by-4-trillion-a-year-according-to-new-research
- LLM in call centers: On average, they saw a 14% improvement in chat completion time with the new tool
	- https://www.nber.org/papers/w31161
	- However, productivity decreased when this technology was used on tasks where the LLMs had poor data coverage or required reasoning that was unlikely to be represented in online text.
	- Over time, external conditions (e.g., cultural values, known best practices) can materially change, causing benefits to either disappear or even lead to significant productivity decreases.
	- Organizations need to take a nuanced, data-driven approach to adopting LLMs.
		- Leaders should consider where this technology actually helps and resist the urge to integrate it into every job and task throughout the organization
		- Two core problems of LLMs that are critical to their medium- and long-term business implications
			- 1)  Its persistent ability to produce convincing falsities
			- 2) The likely long-term negative effects of using LLMs on employees and internal processes.
	- Importantly, notice that this model doesn’t have any concept of truth or fact (it was trained on the internet, after all). LLMs provide answers that are statistically likely to occur in public text
	- LLM does not know the truth in fact can fabricate data consistently. 
		- Google Bard fabricated emails that never were sent https://www.nytimes.com/2023/09/20/technology/google-bard-extensions.html
	- It's stuck in the past
		- A new product would have no data - so how would you train it?
		- Call center example - there are no chat logs - since is a new product.
		- Even assuming the answer was right in the past - could be completely wrong in the future.
			- You might say - ok we re-trained. but what if the marketing strategy has changed?
			- What IF the API has changed, an AI does not know or is not aware of?
		- Companies will need to have processes to monitor these conflicts.
			- Change in task completion speed is easy to measure
			- Change in accuracy is much harder to detect
			- Remember, reproducing the behavior of top performers doesn’t help their performance; in the above study, it hindered it. If they’re getting paid less and everyone else is getting paid more, they will become far less likely to engage in the exploratory behavior they previously exhibited to find innovative solutions.
			- systems will need to be continuously retrained by humans in a real environment, and the text they are trained on will be generated at least partially from previous LLM output, this indicates that systems will deliver low or even negative value in a few training cycles
			- LLMs in reinforcing and amplifying biases
			- Copyright and Ethical issues

AI-generated books force Amazon to cap e-book publications to 3 per day
https://arstechnica.com/information-technology/2023/09/ai-generated-books-force-amazon-to-cap-ebook-publications-to-3-per-day/?ref=wheresyoured.at

Amazon Fresh kills “Just Walk Out” shopping tech—it never really worked
"AI" checkout was actually powered by 1,000 human video reviewers in India.
https://arstechnica.com/gadgets/2024/04/amazon-ends-ai-powered-store-checkout-which-needed-1000-video-reviewers/

Gen AI: too much spend, too little benefit?
https://www.goldmansachs.com/intelligence/pages/gen-ai-too-much-spend-too-little-benefit.html

---

Good Stuff

Automated Unit Test Improvement using Large Language Models at Meta
https://arxiv.org/abs/2402.09171

Transformers
https://huggingface.co/learn/nlp-course/chapter1/4









